{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bab0503f"
      },
      "source": [
        "<center>\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mfranzon/yolo-training-template/blob/main/notebooks/yolo_template.ipynb)   \n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFpu15nn9TYM",
        "outputId": "6b6b604d-e065-4b9a-eeaf-5d1fcf7533fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q\n",
        "!pip install opencv-python -q\n",
        "!pip install matplotlib -q\n",
        "!pip install kagglehub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XcYdPAlt9iD0",
        "outputId": "0a02a4ee-defb-485e-d5df-b6df2cfc653b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import yaml\n",
        "import kagglehub\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    IS_COLAB = True\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kFtYFAgG9liY"
      },
      "outputs": [],
      "source": [
        "def download_dataset(dataset_handle):\n",
        "    \"\"\"Download the Kaggle dataset.\"\"\"\n",
        "    try:\n",
        "        path = kagglehub.dataset_download(dataset_handle)\n",
        "        logging.info(f\"Downloaded dataset to: {path}\")\n",
        "        return path\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to download dataset: {e}\")\n",
        "        raise\n",
        "\n",
        "def detect_dataset_structure(dataset_path):\n",
        "    \"\"\"Detect train/val/test images and labels paths in the dataset.\"\"\"\n",
        "    paths = {}\n",
        "    subdirs = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "    logging.info(f\"Detected subdirs in dataset: {subdirs}\")\n",
        "    splits = ['train', 'valid', 'test']\n",
        "    for split in splits:\n",
        "        key_split = 'val' if split == 'valid' else split\n",
        "        if split in subdirs:\n",
        "            split_dir = os.path.join(dataset_path, split)\n",
        "            images_dir = os.path.join(split_dir, 'images')\n",
        "            labels_dir = os.path.join(split_dir, 'labels')\n",
        "            if os.path.exists(images_dir):\n",
        "                paths[f'{key_split}_images'] = images_dir\n",
        "            if os.path.exists(labels_dir):\n",
        "                paths[f'{key_split}_labels'] = labels_dir\n",
        "    if not paths:\n",
        "        # Check one level deeper\n",
        "        for subdir in subdirs:\n",
        "            sub_path = os.path.join(dataset_path, subdir)\n",
        "            if os.path.isdir(sub_path):\n",
        "                inner_subdirs = [d for d in os.listdir(sub_path) if os.path.isdir(os.path.join(sub_path, d))]\n",
        "                logging.info(f\"Checking inner subdirs in {subdir}: {inner_subdirs}\")\n",
        "                for split in splits:\n",
        "                    key_split = 'val' if split == 'valid' else split\n",
        "                    if split in inner_subdirs:\n",
        "                        split_dir = os.path.join(sub_path, split)\n",
        "                        images_dir = os.path.join(split_dir, 'images')\n",
        "                        labels_dir = os.path.join(split_dir, 'labels')\n",
        "                        if os.path.exists(images_dir):\n",
        "                            paths[f'{key_split}_images'] = images_dir\n",
        "                        if os.path.exists(labels_dir):\n",
        "                            paths[f'{key_split}_labels'] = labels_dir\n",
        "                if paths:\n",
        "                    dataset_path = sub_path\n",
        "                    break\n",
        "        if not paths:\n",
        "            # Check two levels deeper\n",
        "            for subdir in subdirs:\n",
        "                sub_path = os.path.join(dataset_path, subdir)\n",
        "                if os.path.isdir(sub_path):\n",
        "                    inner_subdirs = [d for d in os.listdir(sub_path) if os.path.isdir(os.path.join(sub_path, d))]\n",
        "                    for inner_subdir in inner_subdirs:\n",
        "                        inner_path = os.path.join(sub_path, inner_subdir)\n",
        "                        if os.path.isdir(inner_path):\n",
        "                            deepest_subdirs = [d for d in os.listdir(inner_path) if os.path.isdir(os.path.join(inner_path, d))]\n",
        "                            logging.info(f\"Checking deepest subdirs in {inner_subdir}: {deepest_subdirs}\")\n",
        "                            for split in splits:\n",
        "                                key_split = 'val' if split == 'valid' else split\n",
        "                                if split in deepest_subdirs:\n",
        "                                    split_dir = os.path.join(inner_path, split)\n",
        "                                    images_dir = os.path.join(split_dir, 'images')\n",
        "                                    labels_dir = os.path.join(split_dir, 'labels')\n",
        "                                    if os.path.exists(images_dir):\n",
        "                                        paths[f'{key_split}_images'] = images_dir\n",
        "                                    if os.path.exists(labels_dir):\n",
        "                                        paths[f'{key_split}_labels'] = labels_dir\n",
        "                            if paths:\n",
        "                                dataset_path = inner_path\n",
        "                                break\n",
        "                    if paths:\n",
        "                        break\n",
        "    logging.info(f\"Detected paths: {paths}\")\n",
        "    return paths, dataset_path\n",
        "\n",
        "def create_yaml(dataset_path, paths, nc, names):\n",
        "    \"\"\"Create the data.yaml file for YOLO training.\"\"\"\n",
        "    data_yaml = {\n",
        "        \"path\": dataset_path,\n",
        "        \"train\": os.path.relpath(paths.get('train_images', ''), dataset_path) if 'train_images' in paths else '',\n",
        "        \"val\": os.path.relpath(paths.get('val_images', ''), dataset_path) if 'val_images' in paths else '',\n",
        "        \"test\": os.path.relpath(paths.get('test_images', ''), dataset_path) if 'test_images' in paths else '',\n",
        "        \"nc\": nc,\n",
        "        \"names\": names,\n",
        "    }\n",
        "    yaml_path = f\"{os.path.basename(dataset_path)}.yaml\"\n",
        "    with open(yaml_path, \"w\") as f:\n",
        "        yaml.dump(data_yaml, f)\n",
        "    logging.info(f\"Created YAML config at: {yaml_path}\")\n",
        "    return yaml_path\n",
        "\n",
        "def train_model(yaml_path, epochs, imgsz, batch, device, project, name):\n",
        "    \"\"\"Train the YOLO model.\"\"\"\n",
        "    model = YOLO(\"yolov8m.pt\")\n",
        "    results = model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=epochs,\n",
        "        imgsz=imgsz,\n",
        "        batch=batch,\n",
        "        device=device,\n",
        "        project=project,\n",
        "        name=name,\n",
        "        exist_ok=True,\n",
        "    )\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7wp4lD1A9z7J"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    \"\"\"Load the YOLO model from the specified path.\"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "    logging.info(f\"Model loaded from {model_path}\")\n",
        "    return model\n",
        "\n",
        "def infer_image(model, image_path, conf_thresh=0.5, save_path=None):\n",
        "    \"\"\"Perform inference on a single image.\"\"\"\n",
        "    if not os.path.exists(image_path):\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "    img = cv2.imread(image_path)\n",
        "    results = model(img, conf=conf_thresh)\n",
        "    annotated = results[0].plot()\n",
        "    if save_path:\n",
        "        cv2.imwrite(save_path, annotated)\n",
        "        logging.info(f\"Annotated image saved to {save_path}\")\n",
        "    else:\n",
        "        if IS_COLAB:\n",
        "            cv2_imshow(annotated)\n",
        "        else:\n",
        "            cv2.imshow(\"Inference\", annotated)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "def infer_video(model, video_path, conf_thresh=0.5, save_path=None):\n",
        "    \"\"\"Perform inference on a video file.\"\"\"\n",
        "    if not os.path.exists(video_path):\n",
        "        raise FileNotFoundError(f\"Video not found: {video_path}\")\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Cannot open video: {video_path}\")\n",
        "    if save_path:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        out = cv2.VideoWriter(save_path, fourcc, fps, (width, height))\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        results = model(frame, conf=conf_thresh)\n",
        "        annotated = results[0].plot()\n",
        "        if save_path:\n",
        "            out.write(annotated)\n",
        "        else:\n",
        "            if IS_COLAB:\n",
        "                cv2_imshow(annotated)\n",
        "            else:\n",
        "                cv2.imshow(\"Inference\", annotated)\n",
        "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "                    break\n",
        "        frame_count += 1\n",
        "        if frame_count % 100 == 0:\n",
        "            logging.info(f\"Processed {frame_count} frames\")\n",
        "    cap.release()\n",
        "    if save_path:\n",
        "        out.release()\n",
        "        logging.info(f\"Annotated video saved to {save_path}\")\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def infer_webcam(model, conf_thresh=0.5):\n",
        "    \"\"\"Perform real-time inference on webcam feed.\"\"\"\n",
        "    if IS_COLAB:\n",
        "      raise ValueError(\"Webcam inference is not supported in Google Colab.\")\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(\"Cannot access webcam\")\n",
        "    logging.info(\"Starting webcam inference. Press 'q' to quit.\")\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        results = model(frame, conf=conf_thresh)\n",
        "        annotated = results[0].plot()\n",
        "        cv2.imshow(\"Webcam Inference\", annotated)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZfyM9HWT98Iq"
      },
      "outputs": [],
      "source": [
        "# Example regarding potholes\n",
        "\n",
        "dataset_handle = 'jocelyndumlao/multi-weather-pothole-detection-mwpd'  # Kaggle dataset handle\n",
        "nc = 1  # Number of classes\n",
        "names = ['Potholes']  # Class names\n",
        "epochs = 1  # Training epochs\n",
        "imgsz = 512  # Image size\n",
        "batch = 32  # Batch size\n",
        "device = '0'  # Device: '0' for GPU, 'cpu' for CPU\n",
        "project = 'runs/train'  # Project dir\n",
        "name = 'yolo_train'  # Experiment name\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DiwGD1sI-DXO",
        "outputId": "03a2705b-0653-430f-8576-14b8b50249da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jocelyndumlao/multi-weather-pothole-detection-mwpd?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 231M/231M [00:12<00:00, 19.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8m.pt to 'yolov8m.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 49.7MB 269.3MB/s 0.2s\n",
            "Ultralytics 8.4.14 üöÄ Python-3.12.12 torch-2.10.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=MWPD.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolo_train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/runs/train/yolo_train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 131.1MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, 16, None, [192, 384, 576]]\n",
            "Model summary: 170 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 297.6MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1786.1¬±666.0 MB/s, size: 69.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/.cache/kagglehub/datasets/jocelyndumlao/multi-weather-pothole-detection-mwpd/versions/1/Multi-Weather Pothole Detection (MWPD)/MWPD/train/labels... 2730 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2730/2730 2.4Kit/s 1.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /root/.cache/kagglehub/datasets/jocelyndumlao/multi-weather-pothole-detection-mwpd/versions/1/Multi-Weather Pothole Detection (MWPD)/MWPD/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 601.6¬±480.4 MB/s, size: 56.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /root/.cache/kagglehub/datasets/jocelyndumlao/multi-weather-pothole-detection-mwpd/versions/1/Multi-Weather Pothole Detection (MWPD)/MWPD/valid/labels... 260 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 260/260 1.6Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /root/.cache/kagglehub/datasets/jocelyndumlao/multi-weather-pothole-detection-mwpd/versions/1/Multi-Weather Pothole Detection (MWPD)/MWPD/valid/labels.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Plotting labels to /content/runs/detect/runs/train/yolo_train/labels.jpg... \n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/runs/train/yolo_train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        1/1      8.02G       1.95       2.09      1.844         45        512: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 86/86 1.5it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.9s/it 9.4s\n",
            "                   all        260        573     0.0151      0.115    0.00535     0.0015\n",
            "\n",
            "1 epochs completed in 0.020 hours.\n",
            "Optimizer stripped from /content/runs/detect/runs/train/yolo_train/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from /content/runs/detect/runs/train/yolo_train/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating /content/runs/detect/runs/train/yolo_train/weights/best.pt...\n",
            "Ultralytics 8.4.14 üöÄ Python-3.12.12 torch-2.10.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "Model summary (fused): 93 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0s/it 9.8s\n",
            "                   all        260        573     0.0151      0.115    0.00564    0.00162\n",
            "Speed: 0.2ms preprocess, 7.7ms inference, 0.0ms loss, 10.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/runs/train/yolo_train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "dataset_path = download_dataset(dataset_handle)\n",
        "logging.info(f\"Dataset downloaded to: {dataset_path}\")\n",
        "paths, dataset_path = detect_dataset_structure(dataset_path)\n",
        "if not paths:\n",
        "    raise ValueError(\"No standard train/val/test structure found in dataset\")\n",
        "yaml_path = create_yaml(dataset_path, paths, nc, names)\n",
        "results = train_model(yaml_path, epochs, imgsz, batch, device, project, name)\n",
        "logging.info(\"Training completed successfully\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "728PP1caWwDF",
        "outputId": "b6114b71-43f8-449b-c657-cb5f859db19e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_PgiU06A7bp"
      },
      "outputs": [],
      "source": [
        "model_path = 'runs/train/yolo_train/weights/best.pt'  # Path to trained model\n",
        "input_source = 'highway.mp4'  # 'path/to/image.jpg', 'path/to/video.mp4', or 'webcam'\n",
        "conf_thresh = 0.5  # Confidence threshold\n",
        "output_path = ''  # Optional: 'annotated.jpg' or 'annotated.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIC8nz1TBBXP"
      },
      "outputs": [],
      "source": [
        "model = load_model(model_path)\n",
        "input_lower = input_source.lower()\n",
        "if input_lower == 'webcam':\n",
        "    infer_webcam(model, conf_thresh)\n",
        "elif input_lower.endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tiff')):\n",
        "    infer_image(model, input_source, conf_thresh, output_path)\n",
        "elif input_lower.endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv')):\n",
        "    infer_video(model, input_source, conf_thresh, output_path)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported input type. Use image/video path or 'webcam'\")\n",
        "logging.info(\"Inference completed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0at73i0kGMnR"
      },
      "outputs": [],
      "source": [
        "# run validation script\n",
        "\n",
        "# set parameters\n",
        "target_model_path = '' # set the path to the model you want to benchmark\n",
        "validation_dataset_handle = '' # kaggle handle for validation dataset\n",
        "val_results_path = '' # save path for validation results\n",
        "# name = '' # optionally set a name for the validation run\n",
        "\n",
        "# download dataset\n",
        "dataset_path = download_dataset(validation_dataset_handle) # downloads the dataset and returns the path\n",
        "paths, validation_dataset_path = detect_dataset_structure(dataset_path) # find the path to 'data.yaml' in the validation set\n",
        "yaml_path = f\"{validation_dataset_path}/data.yaml\" # construct the path to data.yaml\n",
        "model=YOLO(target_model_path)\n",
        "\n",
        "# run it & get results\n",
        "results = model.val(data=yaml_path, imgsz=512, split='test', project=val_results_path, name=name) # gets name from cell 5 unless you spec name above\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}